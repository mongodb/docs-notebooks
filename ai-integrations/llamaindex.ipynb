{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB Vector Search - LlamaIndex Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a companion to the [LlamaIndex Get Started](https://www.mongodb.com/docs/atlas/ai-integrations/llamaindex/) page. Refer to the page for set-up instructions and detailed explanations.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mongodb/docs-notebooks/blob/main/ai-integrations/llamaindex.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install --quiet --upgrade llama-index llama-index-vector-stores-mongodb llama-index-llms-openai llama-index-embeddings-voyageai pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"VOYAGEAI_API_KEY\"] = \"<voyageai-api-key>\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<openai-api-key>\"\n",
    "MONGODB_URI = \"<connection-string>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.voyageai import VoyageEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.settings import Settings\n",
    "\n",
    "embed_model= VoyageEmbedding(\n",
    "  voyage_api_key = os.environ[\"VOYAGEAI_API_KEY\"],\n",
    "  model_name = \"voyage-3-large\",\n",
    ")\n",
    "\n",
    "Settings.llm = OpenAI()\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 100\n",
    "Settings.chunk_overlap = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# Load the sample data\n",
    "from urllib.request import urlretrieve\n",
    "urlretrieve(\"https://investors.mongodb.com/node/13176/pdf\", \"mongodb-earnings-report.pdf\")\n",
    "sample_data = SimpleDirectoryReader(input_files=[\"mongodb-earnings-report.pdf\"]).load_data()\n",
    "\n",
    "# Print the first document\n",
    "sample_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.vector_stores.mongodb import MongoDBAtlasVectorSearch\n",
    "\n",
    "# Connect to your MongoDB cluster\n",
    "mongo_client = pymongo.MongoClient(MONGODB_URI)\n",
    "\n",
    "# Instantiate the vector store\n",
    "atlas_vector_store = MongoDBAtlasVectorSearch(\n",
    "    mongo_client,\n",
    "    db_name = \"llamaindex_db\",\n",
    "    collection_name = \"test\",\n",
    "    vector_index_name = \"vector_index\"\n",
    ")\n",
    "vector_store_context = StorageContext.from_defaults(vector_store=atlas_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# Store the data as vector embeddings\n",
    "vector_store_index = VectorStoreIndex.from_documents(\n",
    "   sample_data, storage_context=vector_store_context, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.operations import SearchIndexModel\n",
    "import time\n",
    "\n",
    "# Specify the collection for which to create the index\n",
    "collection = mongo_client[\"llamaindex_db\"][\"test\"]\n",
    "\n",
    "# Create your index model, then create the search index\n",
    "search_index_model = SearchIndexModel(\n",
    "  definition={\n",
    "    \"fields\": [\n",
    "      {\n",
    "        \"type\": \"vector\",\n",
    "        \"path\": \"embedding\",\n",
    "        \"numDimensions\": 1024,\n",
    "        \"similarity\": \"cosine\"\n",
    "      },\n",
    "      {\n",
    "        \"type\": \"filter\",\n",
    "        \"path\": \"metadata.page_label\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  name=\"vector_index\",\n",
    "  type=\"vectorSearch\",\n",
    ")\n",
    "result = collection.create_search_index(model=search_index_model)\n",
    "\n",
    "# Wait for initial sync to complete\n",
    "print(\"Polling to check if the index is ready. This may take up to a minute.\")\n",
    "predicate=None\n",
    "if predicate is None:\n",
    "  predicate = lambda index: index.get(\"queryable\") is True\n",
    "\n",
    "while True:\n",
    "  indices = list(collection.list_search_indexes(result))\n",
    "  if len(indices) and predicate(indices[0]):\n",
    "    break\n",
    "  time.sleep(5)\n",
    "print(result + \" is ready for querying.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store_index.as_retriever(similarity_top_k=3)\n",
    "nodes = retriever.retrieve(\"MongoDB acquisition\")\n",
    "\n",
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search with Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilter, MetadataFilters, ExactMatchFilter, FilterOperator\n",
    "\n",
    "# Specify metadata filters\n",
    "metadata_filters = MetadataFilters(\n",
    "   filters=[ExactMatchFilter(key=\"metadata.page_label\", value=\"2\")]\n",
    ")\n",
    "retriever = vector_store_index.as_retriever(similarity_top_k=3, filters=metadata_filters)\n",
    "nodes = retriever.retrieve(\"MongoDB acquisition\")\n",
    "\n",
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "import pprint\n",
    "\n",
    "# Instantiate MongoDB Vector Search as a retriever\n",
    "vector_store_retriever = VectorIndexRetriever(index=vector_store_index, similarity_top_k=5)\n",
    "\n",
    "# Pass the retriever into the query engine\n",
    "query_engine = RetrieverQueryEngine(retriever=vector_store_retriever)\n",
    "\n",
    "# Prompt the LLM\n",
    "response = query_engine.query(\"What was MongoDB's latest acquisition?\")\n",
    "\n",
    "print(response)\n",
    "print(\"\\nSource documents: \")\n",
    "pprint.pprint(response.source_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG with Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "import pprint\n",
    "\n",
    "# Specify metadata filters\n",
    "metadata_filters = MetadataFilters(\n",
    "   filters=[ExactMatchFilter(key=\"metadata.page_label\", value=\"2\")]\n",
    ")\n",
    "\n",
    "# Instantiate MongoDB Vector Search as a retriever\n",
    "vector_store_retriever = VectorIndexRetriever(index=vector_store_index, filters=metadata_filters, similarity_top_k=5)\n",
    "\n",
    "# Pass the retriever into the query engine\n",
    "query_engine = RetrieverQueryEngine(retriever=vector_store_retriever)\n",
    "\n",
    "# Prompt the LLM\n",
    "response = query_engine.query(\"What was MongoDB's latest acquisition?\")\n",
    "\n",
    "print(response)\n",
    "print(\"\\nSource documents: \")\n",
    "pprint.pprint(response.source_nodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
