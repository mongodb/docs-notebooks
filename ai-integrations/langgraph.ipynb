{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kMALXaMv-MS"
   },
   "source": [
    "# LangGraph MongoDB Integration - Agentic RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a companion to the [Build AI Agents with LangGraph and MongoDB](https://www.mongodb.com/docs/atlas/ai-integrations/langgraph/build-agents) page. For the complete Python application and detailed explanations of the code, refer to the tutorial on the page.\n",
    "\n",
    "This notebook takes you through how to use LangGraph to implement agentic RAG and agent memory (short and long-term) \n",
    "by using MongoDB as the vector database, LangChain to implement retrieval tools, and LangGraph to orchestrate the agent workflow.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mongodb/docs-notebooks/blob/main/ai-integrations/langgraph.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "\n",
    "Check the requirements of the\n",
    "[langchain-voyageai](https://pypi.org/project/langchain-voyageai/) package\n",
    "to ensure you're using a compatible Python version.\n",
    "\n",
    "Before you begin, load the `sample_mflix` dataset into your MongoDB cluster if you haven't already. To learn more, see [Sample Data](https://www.mongodb.com/docs/atlas/sample-data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxTXczeTghzU",
    "outputId": "ae3a81b2-cba6-42fc-f593-8646bff77b14",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install --quiet --upgrade langgraph langgraph-checkpoint-mongodb langgraph-store-mongodb langchain langchain-mongodb langchain-voyageai langchain-openai pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXLWCWEghuOX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"VOYAGE_API_KEY\"] = \"<voyage-api-key>\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<openai-api-key>\"\n",
    "MONGODB_URI = \"<connection-string>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUf3jtFzO4-V"
   },
   "source": [
    "## Use MongoDB as a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_voyageai import VoyageAIEmbeddings\n",
    "\n",
    "embedding_model = VoyageAIEmbeddings(\n",
    "    model = \"voyage-3-large\",\n",
    "    output_dimension = 2048\n",
    ")\n",
    "\n",
    "# Instantiate the vector store\n",
    "vector_store = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "   connection_string = MONGODB_URI,\n",
    "   namespace = \"sample_mflix.embedded_movies\",\n",
    "   embedding = embedding_model,\n",
    "   text_key = \"plot\",\n",
    "   embedding_key = \"plot_embedding_voyage_3_large\",\n",
    "   relevance_score_fn = \"dotProduct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use helper method to create the vector search index\n",
    "vector_store.create_vector_search_index(\n",
    "   dimensions = 2048, # The dimensions of the vector embeddings to be indexed \n",
    "   wait_until_complete = 60 # Number of seconds to wait for the index to build (can take around a minute)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb.index import create_fulltext_search_index\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to your cluster\n",
    "client = MongoClient(MONGODB_URI)\n",
    "collection = client[\"sample_mflix\"][\"embedded_movies\"]\n",
    "\n",
    "# Use helper method to create the search index\n",
    "create_fulltext_search_index( \n",
    "   collection = collection,\n",
    "   field = \"title\",\n",
    "   index_name = \"search_index\",\n",
    "   wait_until_complete = 60 # Number of seconds to wait for the index to build (can take around a minute)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZfheX5FiIhU"
   },
   "source": [
    "## Define search tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "\n",
    "# Define a vector search tool\n",
    "@tool\n",
    "def plot_search(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve information using vector search to answer a user query.\n",
    "    \"\"\"\n",
    "    \n",
    "    retriever = vector_store.as_retriever(\n",
    "       search_type = \"similarity\",\n",
    "       search_kwargs = { \"k\": 5 } # Retrieve top 5 most similar documents\n",
    "    )\n",
    "\n",
    "    results = retriever.invoke(user_query)\n",
    "   \n",
    "    # Concatenate the results into a string\n",
    "    context = \"\\n\\n\".join([f\"{doc.metadata['title']}: {doc.page_content}\" for doc in results])\n",
    "    return context\n",
    "\n",
    "# Test the tool\n",
    "test_results = plot_search.invoke(\"What are some movies that take place in the ocean?\")\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb.retrievers.full_text_search import MongoDBAtlasFullTextSearchRetriever\n",
    "\n",
    "# Define a full-text search tool\n",
    "@tool\n",
    "def title_search(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve movie plot content based on the provided title.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the retriever\n",
    "    retriever = MongoDBAtlasFullTextSearchRetriever(\n",
    "       collection = collection,            # MongoDB Collection\n",
    "       search_field = \"title\",             # Name of the field to search\n",
    "       search_index_name = \"search_index\", # Name of the search index\n",
    "       top_k = 1,                          # Number of top results to return       \n",
    "    ) \n",
    "    results = retriever.invoke(user_query)\n",
    "   \n",
    "    for doc in results:\n",
    "      if doc:\n",
    "          return doc.metadata[\"fullplot\"]\n",
    "      else:\n",
    "          return \"Movie not found\"\n",
    "  \n",
    "# Test the tool     \n",
    "title_search.invoke(\"What is the plot of Titanic?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define memory tools (long-term memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from langgraph.store.mongodb import MongoDBStore, create_vector_index_config\n",
    "\n",
    "# Vector search index configuration for memory collection\n",
    "index_config = create_vector_index_config(\n",
    "    embed=embedding_model,\n",
    "    dims=2048,\n",
    "    relevance_score_fn=\"dotProduct\",\n",
    "    fields=[\"content\"]\n",
    ")\n",
    "\n",
    "# Define a tool to save important interactions to a MongoDB collection\n",
    "@tool\n",
    "def save_memory(content: str) -> str:\n",
    "    \"\"\"Save important information to memory.\"\"\"\n",
    "    with MongoDBStore.from_conn_string(\n",
    "        conn_string=MONGODB_URI,\n",
    "        db_name=\"sample_mflix\",\n",
    "        collection_name=\"memories\",\n",
    "        index_config=index_config,\n",
    "        auto_index_timeout=60 # Wait a minute for vector index creation\n",
    "    ) as store:\n",
    "        store.put(\n",
    "            namespace=(\"user\", \"memories\"),\n",
    "            key=f\"memory_{hash(content)}\",\n",
    "            value={\"content\": content}\n",
    "        )\n",
    "    return f\"Memory saved: {content}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool to retrieve important interactions from the collection using vector search\n",
    "@tool\n",
    "def retrieve_memories(query: str) -> str:\n",
    "    \"\"\"Retrieve relevant memories based on a query.\"\"\"\n",
    "    with MongoDBStore.from_conn_string(\n",
    "        conn_string=MONGODB_URI,\n",
    "        db_name=\"sample_mflix\",\n",
    "        collection_name=\"memories\",\n",
    "        index_config=index_config\n",
    "    ) as store:\n",
    "        results = store.search((\"user\", \"memories\"), query=query, limit=3)\n",
    "\n",
    "    if results:\n",
    "        memories = [result.value[\"content\"] for result in results]\n",
    "        return f\"Retrieved memories:\\n\" + \"\\n\".join(memories)\n",
    "    else:\n",
    "        return \"No relevant memories found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the tools\n",
    "save_memory.invoke(\"I don't like sad movies.\")\n",
    "retrieve_memories.invoke(\"What do you know about me?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Create a chat prompt template for the agent, which includes a system prompt and a placeholder for `messages`\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"You are a helpful AI chatbot.\"\n",
    "            \" You are provided with tools to answer questions about movies.\"\n",
    "            \" Think step-by-step and use these tools to get the information required to answer the user query.\"\n",
    "            \" Do not re-run tools unless absolutely necessary.\"\n",
    "            \" If you are not able to get enough information using the tools, reply with I DON'T KNOW.\"\n",
    "            \" You have access to the following tools: {tool_names}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    " \n",
    "tools = [\n",
    "    plot_search,\n",
    "    title_search,\n",
    "    save_memory,\n",
    "    retrieve_memories\n",
    "]\n",
    "\n",
    "# Provide the tool names to the prompt\n",
    "prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "\n",
    "# Prepare the LLM by making the tools and prompt available to the model\n",
    "bind_tools = llm.bind_tools(tools)\n",
    "llm_with_tools = prompt | bind_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 'name' of the tool that the LLM is calling.\n",
    "# Here, we expect the LLM to use the 'plot_search' tool.\n",
    "llm_with_tools.invoke([\"What are some movies that take place in the ocean?\"]).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 'name' of the tool that the LLM is calling.\n",
    "# Here, we expect the LLM to use the 'title_search' tool.\n",
    "llm_with_tools.invoke([\"What's the plot of Titanic?\"]).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 'name' of the tool that the LLM is calling.\n",
    "# Here, we expect the LLM to use the 'save_memory' tool.\n",
    "llm_with_tools.invoke([\"I prefer funny movies.\"]).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the 'name' of the tool that the LLM is calling.\n",
    "# Here, we expect the LLM to use the 'retrieve_memories' tool.\n",
    "llm_with_tools.invoke([\"What do you know about me?\"]).tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Define the graph state\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Instantiate the graph\n",
    "graph = StateGraph(GraphState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "# Define the agent node\n",
    "def agent(state: GraphState) -> Dict[str, List]:\n",
    "    # Get the messages from the graph `state`\n",
    "    messages = state[\"messages\"]\n",
    "    # Invoke `llm_with_tools` with `messages`\n",
    "    result = llm_with_tools.invoke(messages)\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": [result]}\n",
    "\n",
    "# Add nodes using the `add_node` function\n",
    "# The `agent` node should run the `agent` function\n",
    "graph.add_node(\"agent\", agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# Create a map of tool name to tool call\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# Define tools node\n",
    "def tools_node(state: GraphState) -> Dict[str, List]:\n",
    "    result = []\n",
    "    # Get the list of tool calls from messages\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    # Iterate through `tool_calls`\n",
    "    for tool_call in tool_calls:\n",
    "        # Get the tool from `tools_by_name` using the `name` attribute of the `tool_call`\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        # Invoke the `tool` using the `args` attribute of the `tool_call`\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        # Append the result of executing the tool to the `result` list as a ToolMessage\n",
    "        # The `content`` of the message is `observation`\n",
    "        # The `tool_call_id` can be obtained from the `tool_call`\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": result}\n",
    "\n",
    "# The `tools` node should run the `tools_node` function\n",
    "graph.add_node(\"tools\", tools_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "# Add an edge from the START node to the `agent` node\n",
    "graph.add_edge(START, \"agent\")\n",
    "\n",
    "# Add an edge from the `tools` node to the `agent` node\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Define a conditional edge\n",
    "def route_tools(state: GraphState):\n",
    "    \"\"\"\n",
    "    Uses a conditional_edge to route to the tools node if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    # Get messages from graph state\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if len(messages) > 0:\n",
    "        # Get the last AI message from messages\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    \n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "# Add a conditional edge from the `agent` node to the `tools` node\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    route_tools,\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Compile the graph\n",
    "app = graph.compile()\n",
    "\n",
    "# Optionally, visualize the graph\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream outputs from the graph as they pass through its nodes\n",
    "def execute_graph(user_input: str) -> None:\n",
    "    # Add user input to the messages attribute of the graph state\n",
    "    # The role of the message should be \"user\" and content should be `user_input`\n",
    "    input = {\"messages\": [(\"user\", user_input)]}\n",
    "\n",
    "    # Pass input to the graph and stream the outputs\n",
    "    for output in app.stream(input):\n",
    "        for key, value in output.items():\n",
    "            print(f\"Node {key}:\")\n",
    "            print(value)\n",
    "            \n",
    "    print(\"\\n---FINAL ANSWER---\")\n",
    "    print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"What are some movies that take place in the ocean?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_graph(\"What is the plot of Titanic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using long-term memory\n",
    "execute_graph(\"Recommend me some movies based on what you know about me.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable persistence (short-term memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.mongodb import MongoDBSaver\n",
    "\n",
    "# Initialize a MongoDB checkpointer\n",
    "checkpointer = MongoDBSaver(client)\n",
    "\n",
    "# Instantiate the graph with the checkpointer\n",
    "app = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the `execute_graph` function to include the `thread_id` argument\n",
    "def execute_graph(thread_id: str, user_input: str) -> None:\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    input = {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                user_input,\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "    for output in app.stream(input, config):\n",
    "        for key, value in output.items():\n",
    "            print(f\"Node {key}:\")\n",
    "            print(value)\n",
    "            \n",
    "    print(\"\\n---FINAL ANSWER---\")\n",
    "    print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test graph execution with thread ID\n",
    "execute_graph(\"1\", \"What's the plot of Titanic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up question to ensure message history works\n",
    "execute_graph(\"1\", \"What movies are similar to the one I just asked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask question in new session to show that long-term memory works across sessions\n",
    "execute_graph(\"2\", \"Recommend me movies based on what you know about me.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
