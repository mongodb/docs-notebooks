{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain MongoDB Integration - Hybrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a companion to the [LangChain Hybrid Search](https://www.mongodb.com/docs/atlas/ai-integrations/langchain/hybrid-search/) page. Refer to the page for set-up instructions and detailed explanations.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mongodb/docs-notebooks/blob/main/ai-integrations/langchain-hybrid-search.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install --quiet --upgrade langchain langchain-community langchain-core langchain-mongodb langchain-voyageai langchain-openai pymongo pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<api-key>\"\n",
    "os.environ[\"VOYAGE_API_KEY\"] = \"<voyage-api-key>\"\n",
    "MONGODB_URI = \"<connection-string>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_voyageai import VoyageAIEmbeddings\n",
    "\n",
    "# Create the vector store\n",
    "vector_store = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "   connection_string = MONGODB_URI,\n",
    "   embedding = VoyageAIEmbeddings(model = \"voyage-3-large\", output_dimension = 2048),\n",
    "   namespace = \"sample_mflix.embedded_movies\",\n",
    "   text_key = \"plot\",\n",
    "   embedding_key = \"plot_embedding_voyage_3_large\",\n",
    "   relevance_score_fn = \"dotProduct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use helper method to create the vector search index\n",
    "vector_store.create_vector_search_index(\n",
    "   dimensions = 2048, # The dimensions of the vector embeddings to be indexed\n",
    "   wait_until_complete = 60 # Number of seconds to wait for the index to build (can take around a minute)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb.index import create_fulltext_search_index\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connect to your cluster\n",
    "client = MongoClient(MONGODB_URI)\n",
    "\n",
    "# Use helper method to create the search index\n",
    "create_fulltext_search_index(\n",
    "   collection = client[\"sample_mflix\"][\"embedded_movies\"],\n",
    "   field = \"plot\",\n",
    "   index_name = \"search_index\",\n",
    "   wait_until_complete = 60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb.retrievers.hybrid_search import MongoDBAtlasHybridSearchRetriever\n",
    "\n",
    "# Initialize the retriever\n",
    "retriever = MongoDBAtlasHybridSearchRetriever(\n",
    "    vectorstore = vector_store,\n",
    "    search_index_name = \"search_index\",\n",
    "    top_k = 5,\n",
    "    fulltext_penalty = 50,\n",
    "    vector_penalty = 50,\n",
    "    post_filter=[\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"plot_embedding\": 0,\n",
    "                \"plot_embedding_voyage_3_large\": 0\n",
    "            }\n",
    "        }\n",
    "    ])\n",
    "\n",
    "# Define your query\n",
    "query = \"time travel\"\n",
    "\n",
    "# Print results\n",
    "documents = retriever.invoke(query)\n",
    "for doc in documents:\n",
    "   print(\"Title: \" + doc.metadata[\"title\"])\n",
    "   print(\"Plot: \" + doc.page_content)\n",
    "   print(\"Search score: {}\".format(doc.metadata[\"fulltext_score\"]))\n",
    "   print(\"Vector Search score: {}\".format(doc.metadata[\"vector_score\"]))\n",
    "   print(\"Total score: {}\\n\".format(doc.metadata[\"fulltext_score\"] + doc.metadata[\"vector_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import  RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Define a prompt template\n",
    "template = \"\"\"\n",
    "   Use the following pieces of context to answer the question at the end.\n",
    "   {context}\n",
    "   Question: Can you recommend some movies about {query}?\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# Construct a chain to answer questions on your data\n",
    "chain = (\n",
    "   {\"context\": retriever, \"query\": RunnablePassthrough()}\n",
    "   | prompt\n",
    "   | model\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Prompt the chain\n",
    "query = \"time travel\"\n",
    "answer = chain.invoke(query)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
