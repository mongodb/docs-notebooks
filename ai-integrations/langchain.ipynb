{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain MongoDB Integration - Implement RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a companion to the [LangChain Get Started](https://www.mongodb.com/docs/atlas/ai-integrations/langchain/get-started/) tutorial. Refer to the page for set-up instructions and detailed explanations.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mongodb/docs-notebooks/blob/main/ai-integrations/langchain.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install --quiet --upgrade langchain langchain-community langchain-core langchain-mongodb langchain-voyageai langchain-openai pymongo pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"VOYAGE_API_KEY\"] = \"<voyage-api-key>\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<openai-api-key>\"\n",
    "MONGODB_URI = \"<connection-string>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load the PDF\n",
    "loader = PyPDFLoader(\"https://investors.mongodb.com/node/13176/pdf\")\n",
    "data = loader.load()\n",
    "\n",
    "# Split PDF into documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "# Print the first document\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_voyageai import VoyageAIEmbeddings\n",
    "\n",
    "# Instantiate the vector store using your MongoDB connection string\n",
    "vector_store = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "  connection_string = MONGODB_URI,\n",
    "  namespace = \"langchain_db.test\",\n",
    "  embedding =  VoyageAIEmbeddings(model=\"voyage-3-large\"),\n",
    "  index_name = \"vector_index\"\n",
    ")\n",
    "\n",
    "# Add documents to the vector store\n",
    "vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use helper method to create the vector search index\n",
    "vector_store.create_vector_search_index(\n",
    "   dimensions = 1024, # The dimensions of the vector embeddings to be indexed\n",
    "   filters = [ \"page_label\" ],\n",
    "   wait_until_complete = 60 # Number of seconds to wait for the index to build (can take around a minute)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "query = \"MongoDB acquisition\"\n",
    "results = vector_store.similarity_search(query)\n",
    "\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search with Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"MongoDB acquisition\"\n",
    "results = vector_store.similarity_search_with_score(\n",
    "   query = query, k = 3\n",
    ")\n",
    "\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search with Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"MongoDB acquisition\"\n",
    "\n",
    "results = vector_store.similarity_search_with_score(\n",
    "   query = query,\n",
    "   k = 3,\n",
    "   pre_filter = { \"page_label\": { \"$eq\": 2 } }\n",
    ")\n",
    "\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Instantiate MongoDB Vector Search as a retriever\n",
    "retriever = vector_store.as_retriever(\n",
    "   search_type = \"similarity\",\n",
    "   search_kwargs = { \"k\": 10 }\n",
    ")\n",
    "\n",
    "# Define a prompt template\n",
    "template = \"\"\"\n",
    "\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "def format_docs(docs):\n",
    "   return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Construct a chain to answer questions on your data\n",
    "rag_chain = (\n",
    "   { \"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "   | custom_rag_prompt\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Prompt the chain\n",
    "question = \"What was MongoDB's latest acquisition?\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(\"Question: \" + question)\n",
    "print(\"Answer: \" + answer)\n",
    "\n",
    "# Return source documents\n",
    "documents = retriever.invoke(question)\n",
    "print(\"\\nSource documents:\")\n",
    "pprint.pprint(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG with Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate MongoDB Vector Search as a retriever\n",
    "retriever = vector_store.as_retriever(\n",
    "   search_type = \"similarity\",\n",
    "   search_kwargs = {\n",
    "      \"k\": 10,\n",
    "      \"score_threshold\": 0.75,\n",
    "      \"pre_filter\": { \"page_label\": { \"$eq\": 2 } }\n",
    "   }\n",
    ")\n",
    "\n",
    "# Define a prompt template\n",
    "template = \"\"\"\n",
    "\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "def format_docs(docs):\n",
    "   return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Construct a chain to answer questions on your data\n",
    "rag_chain = (\n",
    "   { \"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "   | custom_rag_prompt\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Prompt the chain\n",
    "question = \"What was MongoDB's latest acquisition?\"\n",
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(\"Question: \" + question)\n",
    "print(\"Answer: \" + answer)\n",
    "\n",
    "# Return source documents\n",
    "documents = retriever.invoke(question)\n",
    "print(\"\\nSource documents:\")\n",
    "pprint.pprint(documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
